{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Профилирование модели\n",
    "\n",
    "Одним из первых шагов для анализа вычислительной сложности модели является ее профилирование.\n",
    "\n",
    "Этот пример лучше запускать либо на компьютере с GPU от NVidia, либо в [Google Colab](https://colab.research.google.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "FcXBeP1O7cnY",
    "outputId": "2b081ee6-3006-47a5-8733-ea0c317bc78e"
   },
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NNU-OD9O9ltP"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Let's make sure GPU is available!\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "named_layers = list(dict(model.named_modules()).keys())\n",
    "print('Layers:')\n",
    "for l in named_layers:\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import profile, ProfilerActivity, record_function\n",
    "\n",
    "input = torch.randn(1, 3, 224, 224).to(device)\n",
    "\n",
    "# Warm-up\n",
    "model(input)\n",
    "\n",
    "activities = [ProfilerActivity.CPU]\n",
    "if torch.cuda.is_available():\n",
    "    activities += [ProfilerActivity.CUDA]\n",
    "\n",
    "with profile(activities=activities, profile_memory=True, record_shapes=True, acc_events=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        output = model(input)\n",
    "\n",
    "sort_key = device.type + \"_time_total\"\n",
    "\n",
    "print(prof.key_averages().table(sort_by=sort_key))\n",
    "\n",
    "prof.export_chrome_trace(\"trace.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HotdogOrNot.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
